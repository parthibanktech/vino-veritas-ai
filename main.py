from fastapi import FastAPI, HTTPException, UploadFile, File
from pydantic import BaseModel
import joblib
import pandas as pd
import numpy as np
import io
from scipy.stats import gaussian_kde
from fastapi.middleware.cors import CORSMiddleware

# Initialize FastAPI application
app = FastAPI(
    title="Vino Veritas Wine Quality API",
    description="Backend API for predicting red wine quality and analyzing chemical drivers.",
    version="1.0.0"
)

# Enable CORS (Cross-Origin Resource Sharing)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Global variables for the ML model and scaler
# These artifacts are generated by running 'wine_analysis.py'
try:
    model = joblib.load("wine_model.joblib")
    scaler = joblib.load("scaler.joblib")
    print("AI Model and Scaler loaded successfully.")
except Exception as e:
    print(f"CRITICAL: Error loading model files: {e}")
    print("Ensure you have run 'wine_analysis.py' to generate the .joblib files.")

# Pydantic model for request validation
class WineFeatures(BaseModel):
    fixed_acidity: float
    volatile_acidity: float
    citric_acid: float
    residual_sugar: float
    chlorides: float
    free_sulfur_dioxide: float
    total_sulfur_dioxide: float
    density: float
    pH: float
    sulphates: float
    alcohol: float

@app.get("/")
def read_root():
    return {"message": "Welcome to Vino Veritas Wine Quality API"}

@app.post("/predict")
def predict_quality(features: WineFeatures):
    try:
        data = features.dict()
        df = pd.DataFrame([data])
        df.columns = [col.replace('_', ' ') for col in df.columns]
        # Scale and Predict
        scaled_features = scaler.transform(df)
        # Convert back to DataFrame to preserve feature names and silence warnings
        scaled_df = pd.DataFrame(scaled_features, columns=df.columns)
        prediction = model.predict(scaled_df)
        return {"quality": float(prediction[0])}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/predict/batch")
async def predict_batch(file: UploadFile = File(...)):
    """
    Accepts a CSV file, performs batch prediction, and returns the results.
    """
    try:
        contents = await file.read()
        df = pd.read_csv(io.BytesIO(contents))
        
        # Clean column names to match model expectations
        # We replace underscores with spaces but preserve casing for 'pH'
        df.columns = [col.replace('_', ' ').strip() for col in df.columns]
        
        # Define features with exact casing as used during model training
        required_features = [
            "fixed acidity", "volatile acidity", "citric acid", "residual sugar",
            "chlorides", "free sulfur dioxide", "total sulfur dioxide", "density",
            "pH", "sulphates", "alcohol"
        ]
        
        # Flexibly handle case-insensitive matching for user convenience
        # but normalize to the exact required casing
        column_map = {col.lower(): col for col in df.columns}
        final_columns = []
        for feat in required_features:
            if feat.lower() in column_map:
                df.rename(columns={column_map[feat.lower()]: feat}, inplace=True)
            else:
                raise HTTPException(status_code=400, detail=f"Missing required column: {feat}")

        # Scale and Predict
        features_only = df[required_features]
        scaled_features = scaler.transform(features_only)
        # Convert back to DataFrame to preserve feature names and silence warnings
        scaled_df = pd.DataFrame(scaled_features, columns=required_features)
        predictions = model.predict(scaled_df)
        
        # Add predictions and ensure they are native Python types for JSON serialization
        df['predicted_quality'] = [float(p) for p in predictions]
        
        # Return as JSON (list of records)
        return df.to_dict(orient="records")
    except HTTPException:
        raise
    except Exception as e:
        print(f"Batch Error: {str(e)}") # Log error for debugging
        raise HTTPException(status_code=500, detail=f"Batch processing error: {str(e)}")

@app.get("/features")
def get_features():
    try:
        feature_importances = model.feature_importances_
        features = [
            "fixed acidity", "volatile acidity", "citric acid", "residual sugar",
            "chlorides", "free sulfur dioxide", "total sulfur dioxide", "density",
            "pH", "sulphates", "alcohol"
        ]
        importance_list = [
            {"feature": feat, "importance": float(imp)}
            for feat, imp in zip(features, feature_importances)
        ]
        importance_list.sort(key=lambda x: x["importance"], reverse=True)
        return importance_list
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analytics/correlation")
def get_correlation():
    """
    Returns the correlation matrix of the dataset for heatmap visualization.
    """
    try:
        # Load the latest dataset
        df = pd.read_csv("winequality-red_par.csv")
        corr = df.corr()
        
        # Format for heatmap: [{ x: 'fixed acidity', y: 'alcohol', value: 0.5 }, ...]
        nodes = []
        features = corr.columns.tolist()
        for i, x in enumerate(features):
            for j, y in enumerate(features):
                nodes.append({
                    "x": x,
                    "y": y,
                    "value": round(float(corr.iloc[i, j]), 2)
                })
        
        return {"features": features, "nodes": nodes}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analytics/distributions")
def get_distributions():
    """
    Returns histogram data and KDE curve for all features.
    """
    try:
        df = pd.read_csv("winequality-red_par.csv")
        results = {}
        for col in df.columns:
            if col == 'quality': continue
            
            # Histogram
            counts, bin_edges = np.histogram(df[col], bins=20, density=False)
            
            # KDE calculation
            # We normalize counts to density for the KDE comparison
            kde = gaussian_kde(df[col])
            x_range = np.linspace(df[col].min(), df[col].max(), 100)
            y_kde = kde(x_range)
            
            # Re-scale KDE to match histogram frequency (counts) for visual overlay
            # Histogram area = sum(counts * bin_width)
            # KDE area = 1. So we multiply by total_counts * bin_width
            bin_width = bin_edges[1] - bin_edges[0]
            y_kde_scaled = y_kde * len(df[col]) * bin_width
            
            results[col] = {
                "counts": counts.tolist(),
                "bins": bin_edges.tolist(),
                "kde_x": x_range.tolist(),
                "kde_y": y_kde_scaled.tolist()
            }
        return results
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analytics/quality-dist")
def get_quality_dist():
    """
    Returns the count of wines per quality rating.
    """
    try:
        df = pd.read_csv("winequality-red_par.csv")
        dist = df['quality'].value_counts().sort_index()
        return [{"quality": int(k), "count": int(v)} for k, v in dist.items()]
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/recommendations")
def get_recommendations():
    """
    Generates dynamic AI recommendations based on feature importance.
    """
    try:
        importances = get_features()
        top_feature = importances[0]['feature']
        
        recommendations = {
            "alcohol": "Alcohol is your #1 quality driver. Stricter monitoring of sugar content and yeast activity is critical for consistency.",
            "volatile acidity": "High volatile acidity is degrading scores. Improve winery sanitation and monitor for early spoilage/acetic acid spikes.",
            "sulphates": "Optimal sulphate levels are key for preservation. Fine-tune your potassium bisulphate additions for better aroma.",
            "total sulfur dioxide": "Adjust SO2 levels based on pH. Excessive levels are noticeable to consumers, while low levels risk oxidation.",
            "density": "Density tracks sugar-to-alcohol conversion. Use it as a real-time indicator of fermentation health."
        }
        
        primary_advice = recommendations.get(top_feature, f"Focus on stabilizing {top_feature} as it fluctuates most in your top-tier batches.")
        
        return {
            "primary_driver": top_feature,
            "advice": primary_advice,
            "full_list": importances[:3]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
